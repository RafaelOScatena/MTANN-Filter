{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ba0aa2d-a638-4a5f-a954-af0b3711cf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 16, 16, 64)        128       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 16, 16, 32)        2080      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 16, 16, 16)        528       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 16, 16, 1)         17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2753 (10.75 KB)\n",
      "Trainable params: 2753 (10.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 318\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# Define batch size and other data pipeline operations (e.g., shuffle, repeat, etc.) batch_size = 32\u001b[39;00m\n\u001b[1;32m    317\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)  \u001b[38;5;66;03m# Shuffle the data\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[43mbatch_size\u001b[49m)          \u001b[38;5;66;03m# Batch the data\u001b[39;00m\n\u001b[1;32m    319\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mprefetch(buffer_size\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mAUTOTUNE)  \u001b[38;5;66;03m# Prefetch for better performanc\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# Skip the first N elements and take the next M elements\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "import glob\n",
    "from tensorflow.image import psnr, ssim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Define your MTANN model as a Keras model\n",
    "# Define your MTANN model as a Keras model\n",
    "\n",
    "def custom_activation(x):\n",
    "    return x + custom_constant\n",
    "\n",
    "def create_mtann_model(patch_size, input_shape):\n",
    "    # Define the model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Input layer (specify the input shape)\n",
    "    model.add(keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    # Hidden layers with sigmoid activation\n",
    "    model.add(keras.layers.Dense(64, activation='sigmoid'))\n",
    "    model.add(keras.layers.Dense(32, activation='sigmoid'))\n",
    "    model.add(keras.layers.Dense(16, activation='sigmoid'))\n",
    "\n",
    "    # Output layer with custom activation function\n",
    "    model.add(keras.layers.Dense(1, activation=custom_activation))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "##################################################\n",
    "\n",
    "\n",
    "def reconstruct_image(input_image, patch_size, mtann_model):\n",
    "    output_image = np.zeros(input_image)\n",
    "    \n",
    "    for y in range(0, input_image.shape[0] - patch_size[0] + 1, 1):\n",
    "        for x in range(0, input_image.shape[1] - patch_size[1] + 1, 1):\n",
    "            input_patch = input_image[y:y+patch_size[0], x:x+patch_size[1]]\n",
    "            \n",
    "            # Pass the input patch through your model to get the single-pixel output\n",
    "            single_pixel_output = mtann_model(input_patch)\n",
    "            \n",
    "            # Place the single-pixel output at the corresponding location in the output image\n",
    "            output_image[y:y+1, x:x+1] = single_pixel_output\n",
    "\n",
    "    return output_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_images(input_images, target_images):\n",
    "    normalized_input_images = []\n",
    "    normalized_target_images = []\n",
    "\n",
    "    for input_image, target_image in zip(input_images, target_images):\n",
    "        # Calculate the minimum and maximum values in the input and target images\n",
    "        min_value_input = tf.reduce_min(input_image)\n",
    "        max_value_input = tf.reduce_max(input_image)\n",
    "        min_value_target = tf.reduce_min(target_image)\n",
    "        max_value_target = tf.reduce_max(target_image)\n",
    "\n",
    "        # Normalize input image to [0, 1]\n",
    "        normalized_input_image = (input_image - min_value_input) / (max_value_input - min_value_input)\n",
    "\n",
    "        # Normalize target image to [0, 1]\n",
    "        normalized_target_image = (target_image - min_value_target) / (max_value_target - min_value_target)\n",
    "\n",
    "        normalized_input_images.append(normalized_input_image)\n",
    "        normalized_target_images.append(normalized_target_image)\n",
    "\n",
    "    return normalized_input_images, normalized_target_images\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "\n",
    "\n",
    "\n",
    "# RESISE FOR DATA AUGMENTATION\n",
    "\n",
    "def resize(input_image, real_image, height, width):\n",
    "    \n",
    "  input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "  real_image = tf.image.resize(real_image, [height, width],\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  return input_image, real_image\n",
    "\n",
    "\n",
    "def random_crop(input_image, real_image):\n",
    "  stacked_image = tf.stack([input_image, real_image], axis=0)\n",
    "  cropped_image = tf.image.random_crop(stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 1])\n",
    "\n",
    "  return cropped_image[0], cropped_image[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def random_jitter(input_image, real_image):\n",
    "  # Resizing to 286x286\n",
    "  input_image, real_image = resize(input_image, real_image, 542, 542)\n",
    "\n",
    "  # Random cropping back to 256x256\n",
    "  input_image, real_image = random_crop(input_image, real_image)\n",
    "\n",
    "  def apply_random_flip():\n",
    "        return tf.image.flip_left_right(input_image), tf.image.flip_left_right(real_image)\n",
    "\n",
    "  input_image, real_image = tf.cond(tf.random.uniform(()) > 0.5, apply_random_flip, lambda: (input_image, real_image))\n",
    "\n",
    "  return input_image, real_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PATH = \"/home/rafael/√Årea de Trabalho/Dataset-PNG\"\n",
    "\n",
    "####################################################\n",
    "\n",
    "\n",
    "# Define a custom constant and a custom loss that includes the constant\n",
    "custom_constant = tf.Variable(initial_value=1.0, trainable=True, name='custom_constant')\n",
    "custom_constant_initializer = keras.initializers.Constant(value=1.0)\n",
    "\n",
    "\n",
    "# mtann_model.load_weights('mtann_weights.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "\n",
    "# Split the input and ground truth images into overlapping patches\n",
    "patch_size = (16, 16)\n",
    "stride = (8, 8)\n",
    "input_patches = []\n",
    "gt_patches = []\n",
    "\n",
    "shape=(16, 16, 1)\n",
    "\n",
    "def reconstruct_image_from_patches(patches, image_shape, patch_size, stride):\n",
    "    reconstructed_image = np.zeros(image_shape, dtype=np.float32)\n",
    "    count_map = np.zeros(image_shape, dtype=np.float32)\n",
    "    \n",
    "    for y in range(0, image_shape[0] - patch_size[0] + 1, stride[0]):\n",
    "        for x in range(0, image_shape[1] - patch_size[1] + 1, stride[1]):\n",
    "            patch = patches.pop(0)  # Take the first patch from the list\n",
    "            reconstructed_image[y:y+patch_size[0], x:x+patch_size[1]] += patch\n",
    "            count_map[y:y+patch_size[0], x:x+patch_size[1]] += 1\n",
    "\n",
    "    # Avoid division by zero and compute the average\n",
    "    count_map = np.maximum(count_map, 1)\n",
    "    reconstructed_image /= count_map\n",
    "\n",
    "    return reconstructed_image\n",
    "\n",
    "    \n",
    "def generate_images(input_patches, gt_patches, image_shape, patch_size, stride):\n",
    "  reconstructed_input = reconstruct_image(input_patches)\n",
    "  reconstructed_gt = reconstruct_image(gt_patches)\n",
    "\n",
    "\n",
    "  prediction = np.zeros(reconstructed_input)\n",
    "    \n",
    "  for y in range(0, input_image.shape[0] - patch_size[0] + 1, stride_2[0]):\n",
    "      for x in range(0, input_image.shape[1] - patch_size[1] + 1, stride_2[1]):\n",
    "          input_patch = input_image[y:y+patch_size[0], x:x+patch_size[1]]\n",
    "            \n",
    "          # Pass the input patch through your model to get the single-pixel output\n",
    "          single_pixel_output = mtann_model(input_patch)\n",
    "            \n",
    "          # Place the single-pixel output at the corresponding location in the output image\n",
    "          prediction[y:y+1, x:x+1] = single_pixel_output\n",
    "    \n",
    "    \n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  display_list = [reconstructed_input[0], reconstructed_gt[0], prediction[0]]\n",
    "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
    "\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # Getting the pixel values in the [0, 1] range to plot.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def load2(image_file, patch_size, stride):\n",
    "    image_ts = tf.io.read_file(image_file)\n",
    "    image_ts = tf.image.decode_png(image_ts)\n",
    "\n",
    "    # Calculate the center of the image\n",
    "    w_center = 358\n",
    "\n",
    "    # Split the image into two parts\n",
    "    input_image = image_ts[:, w_center:, :]\n",
    "    real_image = image_ts[:, :w_center, :]\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    real_image = tf.cast(real_image, tf.float32)\n",
    "    \n",
    "    input_image, real_image = resize(input_image, real_image, IMG_HEIGHT, IMG_WIDTH)\n",
    "    \n",
    "    input_patches = []\n",
    "    gt_patches = []\n",
    "\n",
    "    for y in range(0, input_image.shape[0] - patch_size[0] + 1, stride[0]):\n",
    "        for x in range(0, input_image.shape[1] - patch_size[1] + 1, stride[1]):\n",
    "            input_patch = input_image[y:y+patch_size[0], x:x+patch_size[1]]\n",
    "            gt_patch = real_image[y:y+patch_size[0], x:x+patch_size[1]]\n",
    "            input_patches.append(input_patch)\n",
    "            gt_patches.append(gt_patch)\n",
    "\n",
    "    return input_patches, gt_patches, image_file\n",
    "    \n",
    "########## LOAD DATASETS\n",
    " \n",
    "# LOAD TRAIN\n",
    "\n",
    "def load_image_train(image_file):\n",
    "  input_image, real_image, image_file = load2(image_file, patch_size, stride)\n",
    "# input_image, real_image = random_jitter(input_image, real_image)\n",
    "  input_image, real_image = normalize_images(input_image, real_image)\n",
    "  \n",
    "  return input_image, real_image, image_file\n",
    "\n",
    "# LOAD VALIDATION\n",
    "\n",
    "def load_image_val(image_file):\n",
    "  input_image, real_image, image_file = load2(image_file, patch_size, stride)\n",
    "# input_image, real_image = random_jitter(input_image, real_image)\n",
    "  input_image, real_image = normalize_images(input_image, real_image)\n",
    "\n",
    "  return input_image, real_image, image_file\n",
    "\n",
    "\n",
    "# LOAD TEST\n",
    "\n",
    "def load_image_test(image_file):\n",
    "  input_image, real_image, image_file = load2(image_file, patch_size, stride)\n",
    "  input_image, real_image = normalize_images(input_image, real_image)\n",
    "\n",
    "  return input_image, real_image, image_file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############# COMPILE THE MODEL\n",
    "\n",
    "# Define the custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Apply the custom activation within the loss function\n",
    "    y_pred_with_activation = y_pred + custom_constant\n",
    "    # Calculate your custom loss here\n",
    "    # For example, you can use mean squared error (MSE) as a simple loss function\n",
    "    loss = tf.keras.losses.mean_squared_error(y_true, y_pred_with_activation)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Create your MTANN model\n",
    "# Define the input shape\n",
    "\n",
    "input_shape = (16, 16, 1)\n",
    "\n",
    "# Create your MTANN model\n",
    "mtann_model = create_mtann_model(patch_size, input_shape)\n",
    "\n",
    "# Compile the model with your custom loss function\n",
    "mtann_model.compile(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "\n",
    "mtann_model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(mtann_model, show_shapes=True, dpi=64)\n",
    "\n",
    "\n",
    "\n",
    "####### CREATE DATASETS\n",
    "\n",
    "input_directory_train = \"/home/rafael/√Årea de Trabalho/Dataset-PNG\"\n",
    "input_directory_test = \"/home/rafael/√Årea de Trabalho/Dataset-PNG/Test\"\n",
    "input_directory_val = \"/home/rafael/√Årea de Trabalho/Dataset-PNG/Val\"\n",
    "\n",
    "\n",
    "# Use glob to get a list of image file paths in the input directory\n",
    "image_files      = glob.glob(input_directory_train + \"/*.png\")  # Change the file extension as needed\n",
    "image_files_test = glob.glob(input_directory_test + \"/*.png\")  # Change the file extension as needed\n",
    "image_files_val  = glob.glob(input_directory_val + \"/*.png\")  # Change the file extension as needed\n",
    "\n",
    "\n",
    "# Create a dataset from the list of image files\n",
    "dataset = tf.data.Dataset.from_tensor_slices(image_files)\n",
    "dataset = dataset.map(load_image_train)\n",
    "# Define batch size and other data pipeline operations (e.g., shuffle, repeat, etc.) batch_size = 32\n",
    "dataset = dataset.shuffle(buffer_size=1000)  # Shuffle the data\n",
    "dataset = dataset.batch(batch_size)          # Batch the data\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # Prefetch for better performanc\n",
    "\n",
    "# Skip the first N elements and take the next M elements\n",
    "N = 0\n",
    "M = 200\n",
    "dataset = dataset.skip(N).take(M)\n",
    "\n",
    "##\n",
    "# Create a dataset from the list of image files\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(input_directory_val)\n",
    "test_dataset = dataset.map(load_image_train)\n",
    "# Define batch size and other data pipeline operations (e.g., shuffle, repeat, etc.) batch_size = 32\n",
    "test_dataset = dataset.shuffle(buffer_size=1000)  # Shuffle the data\n",
    "test_dataset = dataset.batch(batch_size)          # Batch the data\n",
    "test_dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # Prefetch for better performanc\n",
    "\n",
    "# Skip the first N elements and take the next M elements\n",
    "N = 0\n",
    "M = 100\n",
    "test_dataset = dataset.skip(N).take(M)\n",
    "\n",
    "#\n",
    "# Create a dataset from the list of image files\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(image_files_test)\n",
    "val_dataset = dataset.map(load_image_train)\n",
    "# Define batch size and other data pipeline operations (e.g., shuffle, repeat, etc.) batch_size = 32\n",
    "val_dataset = dataset.shuffle(buffer_size=1000)  # Shuffle the data\n",
    "val_dataset = dataset.batch(batch_size)          # Batch the data\n",
    "val_dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  # Prefetch for better performanc\n",
    "\n",
    "# Skip the first N elements and take the next M elements\n",
    "N = 0\n",
    "M = 100\n",
    "test_dataset = dataset.skip(N).take(M)\n",
    "\n",
    "\n",
    "\n",
    "# Define the checkpoint directory\n",
    "checkpoint_dir = '/home/rafael/√Årea de Trabalho/MTANN Checkpoints/1'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Create a callback to save model weights\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    os.path.join(checkpoint_dir, 'weights.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    mode='min',  # Minimize the monitored quantity (in this case, validation loss)\n",
    "    verbose=1  # Verbosity mode: 1 shows saving messages\n",
    ")\n",
    "\n",
    "\n",
    "losses = []  # To store loss values\n",
    "\n",
    "# Create a callback to save training history (loss) in CSV format\n",
    "csv_logger = CSVLogger(os.path.join(checkpoint_dir, 'training_history.csv'), append=True)\n",
    "\n",
    "\n",
    "# Perform the training loop\n",
    "\n",
    "\n",
    "num_epochs = 10  # Set the number of training epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0  # Track the total loss for this epoch\n",
    "    steps_per_epoch = len(input_patches) // batch_size\n",
    "\n",
    "    # Iterate through the dataset (batches)\n",
    "    for batch_input, batch_gt, batch_finenames in dataset:\n",
    "       # Perform the forward pass to get predictions\n",
    "       single_pixel_output = mtann_model(input_patch)\n",
    "\n",
    "       # Get the center pixel of batch_gt\n",
    "       center_x = batch_gt.shape[1] // 2\n",
    "       center_y = batch_gt.shape[2] // 2\n",
    "       center_pixel = batch_gt[:, center_x, center_y, :]\n",
    "\n",
    "        \n",
    "       # Calculate the mean squared error (MSE) loss\n",
    "       loss = tf.keras.losses.mean_squared_error(center_pixel, single_pixel_output)\n",
    "\n",
    "       # Calculate gradients\n",
    "       grads = mtann_model.optimizer.get_gradients(loss, mtann_model.trainable_variables)\n",
    "\n",
    "       # Apply gradients to update model weights\n",
    "       mtann_model.optimizer.apply_gradients(zip(grads, mtann_model.trainable_variables))\n",
    "\n",
    "       # Track the total loss for this epoch\n",
    "       total_loss += loss\n",
    "\n",
    "    input_patch, input_gt, example_filename = next(iter(test_dataset.take(1)))\n",
    "    image_shape_t=(512,512)\n",
    "    generate_images(input_patch, input_gt, image_shape_t, patch_size, stride)\n",
    "    \n",
    "\n",
    "    # Calculate and print the average loss for this epoch\n",
    "    average_loss = total_loss / steps_per_epoch\n",
    "    losses.append(average_loss.numpy())\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {average_loss.numpy()}\")\n",
    "\n",
    "    checkpoint_callback.on_epoch_end(epoch, logs={'val_loss': average_loss})\n",
    "    csv_logger.on_epoch_end(epoch, logs={'loss': average_loss})\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(checkpoint_dir, 'loss_history.txt'), 'w') as f:\n",
    "    for loss in losses:\n",
    "        f.write(f\"{loss}\\n\")\n",
    "\n",
    "\n",
    "##################################\n",
    "\n",
    "\n",
    "#Initialize lists to store PSNR and SSIM values\n",
    "psnr_train_values = []\n",
    "ssim_train_values = []\n",
    "psnr_test_values = []\n",
    "ssim_test_values = []\n",
    "psnr_validation_values = []\n",
    "ssim_validation_values = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate PSNR and SSIM for the training dataset\n",
    "for batch in train_dataset:\n",
    "    input_image, target_image, filenames_b = batch\n",
    "    \n",
    "    # Generate an image using the trained model\n",
    "\n",
    "    generated_image, target_image = resize(input_image, target_image,IMG_HEIGHT, IMG_WIDTH)\n",
    "    \n",
    "    output_image = np.zeros(input_image)\n",
    "    \n",
    "    for y in range(0, input_image.shape[0] - patch_size[0] + 1, stride_2[0]):\n",
    "        for x in range(0, input_image.shape[1] - patch_size[1] + 1, stride_2[1]):\n",
    "            input_patch = input_image[y:y+patch_size[0], x:x+patch_size[1]]\n",
    "            \n",
    "            # Pass the input patch through your model to get the single-pixel output\n",
    "            single_pixel_output = mtann_model(input_patch)\n",
    "            \n",
    "            # Place the single-pixel output at the corresponding location in the output image\n",
    "            output_image[y:y+1, x:x+1] = single_pixel_output\n",
    "\n",
    "\n",
    "    # Calculate PSNR and SSIM for the generated image compared to the target image\n",
    "    psnr_train = tf.image.psnr(generated_image, target_image, max_val=1.0)\n",
    "    psnr_train = tf.where(tf.math.is_finite(psnr_train), psnr_train, 0.0)\n",
    "    ssim_train = tf.image.ssim(generated_image, target_image, max_val=1.0)\n",
    "    ssim_train = tf.where(tf.math.is_finite(ssim_train), ssim_train, 0.0)\n",
    "\n",
    "    psnr_train_values.append(psnr_train)\n",
    "    ssim_train_values.append(ssim_train)\n",
    "\n",
    "    # Convert the TensorFlow tensor to a NumPy array for visualization\n",
    "\n",
    "\n",
    "    generated_image = generated_image[0]  # Extract the image from the batch\n",
    "    target_image = target_image[0]  # Extract the image from the batch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(generated_image, cmap='gray')\n",
    "    plt.title('Normalized Generated Image')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(target_image, cmap='gray')\n",
    "    plt.title('Target Image')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for batch in test_dataset:\n",
    "    input_image, target_image, filenames_b = batch\n",
    "    \n",
    "    # Generate an image using the trained model\n",
    "\n",
    "    generated_image, target_image = resize(input_image, target_image, IMG_HEIGHT, IMG_WIDTH)\n",
    "    \n",
    "    output_image = np.zeros(input_image)\n",
    "    \n",
    "    for y in range(0, input_image.shape[0] - patch_size[0] + 1, stride_2[0]):\n",
    "        for x in range(0, input_image.shape[1] - patch_size[1] + 1, stride_2[1]):\n",
    "            input_patch = input_image[y:y+patch_size[0], x:x+patch_size[1]]\n",
    "            \n",
    "            # Pass the input patch through your model to get the single-pixel output\n",
    "            single_pixel_output = mtann_model(input_patch)\n",
    "            \n",
    "            # Place the single-pixel output at the corresponding location in the output image\n",
    "            output_image[y:y+1, x:x+1] = single_pixel_output\n",
    "\n",
    "\n",
    "    # Calculate PSNR and SSIM for the generated image compared to the target image\n",
    "    psnr_test = tf.image.psnr(generated_image, target_image, max_val=1.0)\n",
    "    psnr_test = tf.where(tf.math.is_finite(psnr_test), psnr_test, 0.0)\n",
    "    ssim_test = tf.image.ssim(generated_image, target_image, max_val=1.0)\n",
    "    ssim_test = tf.where(tf.math.is_finite(ssim_test), ssim_test, 0.0)\n",
    "\n",
    "    psnr_test_values.append(psnr_test)\n",
    "    ssim_test_values.append(ssim_test)\n",
    "\n",
    "    # Convert the TensorFlow tensor to a NumPy array for visualization\n",
    "\n",
    "    generated_image = generated_image[0]  # Extract the image from the batch\n",
    "    target_image = target_image[0]  # Extract the image from the batch\n",
    "\n",
    "\n",
    "'''\n",
    "for batch in val_dataset:\n",
    "    input_image, target_image, filenames_b = batch\n",
    "    \n",
    "    # Generate an image using the trained model\n",
    "\n",
    "    generated_image, target_image = resize(input_image, target_image, IMG_HEIGHT, IMG_WIDTH)\n",
    "    \n",
    "    output_image = np.zeros(input_image)\n",
    "    \n",
    "    for y in range(0, input_image.shape[0] - patch_size[0] + 1, stride_2[0]):\n",
    "        for x in range(0, input_image.shape[1] - patch_size[1] + 1, stride_2[1]):\n",
    "            input_patch = input_image[y:y+patch_size[0], x:x+patch_size[1]]\n",
    "            \n",
    "            # Pass the input patch through your model to get the single-pixel output\n",
    "            single_pixel_output = mtann_model(input_patch)\n",
    "            \n",
    "            # Place the single-pixel output at the corresponding location in the output image\n",
    "            output_image[y:y+1, x:x+1] = single_pixel_output\n",
    "\n",
    "\n",
    "    # Calculate PSNR and SSIM for the generated image compared to the target image\n",
    "    psnr_val = tf.image.psnr(generated_image, target_image, max_val=1.0)\n",
    "    psnr_val = tf.where(tf.math.is_finite(psnr_val), psnr_val, 0.0)\n",
    "    ssim_val = tf.image.ssim(generated_image, target_image, max_val=1.0)\n",
    "    ssim_val = tf.where(tf.math.is_finite(ssim_val), ssim_val, 0.0)\n",
    "\n",
    "    psnr_val_values.append(psnr_val)\n",
    "    ssim_val_values.append(ssim_val)\n",
    "\n",
    "    # Convert the TensorFlow tensor to a NumPy array for visualization\n",
    "\n",
    "    generated_image = generated_image[0]  # Extract the image from the batch\n",
    "    target_image = target_image[0]  # Extract the image from the batch\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "average_psnr_val = tf.reduce_mean(psnr_val_values).numpy()\n",
    "average_ssim_val = tf.reduce_mean(ssim_val_values).numpy()\n",
    "average_psnr_train = tf.reduce_mean(psnr_train_values).numpy()\n",
    "average_ssim_train = tf.reduce_mean(ssim_train_values).numpy()\n",
    "#average_psnr_test = tf.reduce_mean(psnr_test_values).numpy()\n",
    "#average_ssim_test = tf.reduce_mean(ssim_test_values).numpy()\n",
    "\n",
    "print(f\"Average PSNR for training set: {float(average_psnr_train)}\")\n",
    "print(f\"Average SSIM for training set: {float(average_ssim_train)}\")\n",
    "print(f\"Average PSNR for test set: {float(average_psnr_test)}\")\n",
    "print(f\"Average SSIM for test set: {float(average_ssim_test)}\")\n",
    "#print(f\"Average PSNR for validation set: {float(average_psnr_val)}\")\n",
    "#print(f\"Average SSIM for validation set: {float(average_ssim_val)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec49d369-4c3a-449b-8cd2-54f06d654413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
